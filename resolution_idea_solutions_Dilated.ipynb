{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "resolution_idea_solutions_Dilated.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fw-gSFYIbdu",
        "outputId": "e1f9a4df-9a54-447c-a24e-734e686885e7"
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install thop\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from thop import profile\n",
        "from torchsummary import summary\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting thop\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/8b/22ce44e1c71558161a8bd54471123cc796589c7ebbfc15a7e8932e522f83/thop-0.0.31.post2005241907-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from thop) (1.7.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.8)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.0.31.post2005241907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9c5QX7BgEp4"
      },
      "source": [
        "# training a model first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN6ifgYqgEp4"
      },
      "source": [
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "NUM_RUNS = 3\n",
        "EPOCHS = 10"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT9LC5-AoseA"
      },
      "source": [
        "# m = nn.Conv2d(1, 1, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr39Ia68tUnF"
      },
      "source": [
        "def find_res_params_dilated(N1, C1, P1, S1):\n",
        "  '''\n",
        "    Keeping the number of parameters the same\n",
        "    Approach III in the paper\n",
        "  '''\n",
        "  # N1=20 # orig image size\n",
        "\n",
        "  # # layer 1\n",
        "  # C1=3 # filter size old\n",
        "  # K1=20  # num filters old\n",
        "  # P1=0 # padding old\n",
        "  # S1=1 # stride old\n",
        "\n",
        "  # layer 2\n",
        "  # B1=2 # filter size old\n",
        "  # K3=10 # num filters old\t\n",
        "  # Q1=0 # padding old\n",
        "  # R1=1 # stride old\n",
        "\n",
        "  num_solutions = 0 \n",
        "  Solutions = []\n",
        "\n",
        "  for N2 in np.arange(N1+1,29): # new img resolution\n",
        "    for P2 in np.arange(4): # new padding size in layer 1\n",
        "      for S2 in np.arange(1,3): # new stride in layer 1\n",
        "        for D2 in np.arange(2,4): # new dilation in layer 1      \n",
        "          # import pdb; pdb.set_trace()\n",
        "          M2 = int((N2 - D2*(C1-1) - 1 + 2*P2)  / S2  + 1)\n",
        "          M1 = int((N1 - C1 + 2*P1)  / S1 + 1)\n",
        "\n",
        "          if M2 == M1: \n",
        "            num_solutions += 1\n",
        "            Solutions.append({'im_res_orig':N1, 'im_res_new':N2, 'layer1_old':[C1, P1, S1], 'layer1':[C1, P2, S2, D2]})\n",
        "\n",
        "  # print(f'num solutions: {num_solutions}')\n",
        "  return Solutions"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDttasGMlZ02"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "\n",
        "\n",
        "class NetTest(nn.Module):\n",
        "    def __init__(self, im_res=28, conv1_size=3, conv2_size=3, pool1_size=2, pool2_size=2, num_conv1=10, num_conv2=10, stride_1=1, stride_2=1, padd_1=0, padd_2=0, num_hid=50, dilation_1=1):\n",
        "        super(NetTest, self).__init__()\n",
        "        # import pdb; pdb.set_trace()\n",
        "        self.conv1 = nn.Conv2d(1, num_conv1, kernel_size=conv1_size, stride=stride_1, padding=padd_1, dilation=dilation_1, bias=False)\n",
        "        self.res_conv1 = int((im_res - dilation_1*(conv1_size - 1) - 1 + 2*padd_1) / stride_1 + 1)\n",
        "        self.res_pool1 = int((self.res_conv1 - pool1_size + 2*0) / pool1_size + 1)                \n",
        "\n",
        "        self.conv2 = nn.Conv2d(num_conv1, num_conv2, kernel_size=conv2_size, stride=stride_2, padding=padd_2, bias=False)\n",
        "        \n",
        "        self.res_conv2 = int((self.res_pool1 - conv2_size + 2*padd_2) / stride_2 + 1 )       \n",
        "        self.res_pool2 = int((self.res_conv2 - pool2_size + 2*0) / pool2_size + 1)               \n",
        "        \n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "\n",
        "        self.fc1 = nn.Linear((self.res_pool2**2)*num_conv2, num_hid, bias=False)        \n",
        "        self.fc2 = nn.Linear(num_hid, 10, bias=False)\n",
        "        self.pool1_size = pool1_size\n",
        "        self.pool2_size = pool2_size\n",
        "        self.num_conv2 = num_conv2\n",
        "        self.im_res = im_res\n",
        "\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # import pdb; pdb.set_trace()\n",
        "\n",
        "        tmp1 = F.relu(F.max_pool2d(self.conv1(x), self.pool1_size))\n",
        "        tmp = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(tmp1)), self.pool2_size))\n",
        "        # x = F.avg_pool2d(tmp, kernel_size=tmp.shape[-1])\n",
        "        # x = x[:,:,0,0]\n",
        "\n",
        "        x = tmp.view(-1, (self.res_pool2**2)*self.num_conv2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x   ### SUPER IMPORTANT ***************************** works with cross entropy loss loss now\n",
        "\n",
        "device = 'cuda'\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NINTmFMRDpeM"
      },
      "source": [
        "# c = 6\n",
        "# p = 3\n",
        "# s = 2\n",
        "# assert 20 == (28 - c + 2*p) / s + 1, False\n",
        "# 19 = 22 + 2*6 \n",
        "# import cv2\n"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CGZ2JLFzdgA"
      },
      "source": [
        "def train_model(model):\n",
        "\n",
        "  # EPOCHS = 10\n",
        "  losses = []\n",
        "\n",
        "  optimizer = optim.Adadelta(model.parameters())\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(EPOCHS):\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          \n",
        "          data, target = data.to(device), target.to(device)        \n",
        "          optimizer.zero_grad()\n",
        "          y_pred = model(data) \n",
        "\n",
        "          # import pdb; pdb.set_trace()\n",
        "          loss = F.cross_entropy(y_pred, target)\n",
        "          losses.append(loss.cpu().data)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          # Display\n",
        "          if batch_idx % 100 == 1:\n",
        "              print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch+1,\n",
        "                  EPOCHS,\n",
        "                  batch_idx * len(data), \n",
        "                  len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader), \n",
        "                  loss.cpu().data), \n",
        "                  end='')\n",
        "\n",
        "  # Eval\n",
        "  # model.eval()\n",
        "  # Eval\n",
        "  model.eval()\n",
        "  correct = total = 0\n",
        "  for idx, (images, labels) in enumerate(test_loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      _, pre = torch.max(outputs.data, 1)\n",
        "\n",
        "      total += len(labels)\n",
        "      correct += (pre == labels).sum()\n",
        "\n",
        "  accuracy = float(correct) / total\n",
        "  print('Test Accuracy: %f %%' % accuracy)\n",
        "  # return acc\n",
        "\n",
        "\n",
        "  # import pdb; pdb.set_trace()\n",
        "  # evaluate_x = test_loader.dataset.test_data.type_as(torch.FloatTensor()).to(device)\n",
        "  # evaluate_y = test_loader.dataset.test_labels.to(device)\n",
        "\n",
        "  # output = model(evaluate_x[:,None,...])\n",
        "  # pred = output.data.max(1)[1]\n",
        "  # d = pred.eq(evaluate_y.data).cpu()\n",
        "  # accuracy = d.sum().type(dtype=torch.float64)/d.size()[0]\n",
        "  \n",
        "  print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Test Accuracy: {:.4f}%'.format(\n",
        "      epoch+1,\n",
        "      EPOCHS,\n",
        "      len(train_loader.dataset), \n",
        "      len(train_loader.dataset),\n",
        "      100. * batch_idx / len(train_loader), \n",
        "      loss.cpu().data,\n",
        "      accuracy*100,\n",
        "      end=''))\n",
        "  \n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdlukGiltyP5"
      },
      "source": [
        "# sol_3"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Saj7rxrhL6Z"
      },
      "source": [
        ""
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIedXhFbNK84"
      },
      "source": [
        "def evaluate_orig_model(sol):\n",
        "\n",
        "  # run the original model for a couple of times\n",
        "  # sol = sol_3[0]\n",
        "  sol['orig_solutions'] = []\n",
        "\n",
        "  im_res = sol['im_res_orig']\n",
        "  cv1_size = int(sol['layer1_old'][0])\n",
        "  pd1 = sol['layer1_old'][1]\n",
        "  st1 = sol['layer1_old'][2]\n",
        "\n",
        "  global train_loader\n",
        "  global test_loader\n",
        "  \n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      datasets.FashionMNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
        "              transforms.ToTensor(),transforms.Resize((im_res, im_res)),])), batch_size=100, shuffle=True)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      datasets.FashionMNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
        "              transforms.ToTensor(),transforms.Resize((im_res, im_res)),])), batch_size=100, shuffle=True)\n",
        "\n",
        "  # for run_no in range(1):\n",
        "  try:\n",
        "      # print(f'----  im_res={im_res_new}, conv1_size={cv1_size}, conv2_size={cv2_size}')\n",
        "      # import pdb; pdb.set_trace()\n",
        "    accs = []\n",
        "    for i in range(NUM_RUNS):\n",
        "      model = NetTest(im_res=im_res, conv1_size=cv1_size, padd_1=pd1, stride_1=st1).to(device)\n",
        "      if i==0:\n",
        "        macs, params = profile(model, inputs=(torch.randn(1, 1, im_res, im_res).to(device), ))\n",
        "      accs.append(train_model(model))\n",
        "    \n",
        "    sol['orig_solutions'].append((macs, params, np.mean(accs)))\n",
        "    # accuracies.append((sol, macs, params, acc))\n",
        "    # print(accuracies[-1])\n",
        "    print(sol, '\\n')\n",
        "\n",
        "  except:\n",
        "    print('\\n Model invalid')\n",
        "\n",
        "\n",
        "  return #sol\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chf2kB7wVinf"
      },
      "source": [
        "def evaluate_new_model(sols):\n",
        "  # running the solutions; one by one; three each\n",
        "  # for run_no\n",
        "\n",
        "  for sol in sols:\n",
        "        im_res = sol['im_res_new']\n",
        "        cv1_size = int(sol['layer1'][0])\n",
        "        pd1 = sol['layer1'][1]\n",
        "        st1 = sol['layer1'][2]\n",
        "        dl1 = sol['layer1'][3]\n",
        "\n",
        "\n",
        "        sol['new_solutions'] = []\n",
        "\n",
        "        global train_loader\n",
        "        global test_loader\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            datasets.FashionMNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),transforms.Resize((im_res, im_res)),])), batch_size=100, shuffle=True)\n",
        "\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            datasets.FashionMNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),transforms.Resize((im_res, im_res)),])), batch_size=100, shuffle=True)\n",
        "\n",
        "\n",
        "        # for run_no in range(1):\n",
        "        try:\n",
        "          # print(f'----  im_res={im_res_new}, conv1_size={cv1_size}, conv2_size={cv2_size}')\n",
        "          \n",
        "          accs = []\n",
        "          for i in range(NUM_RUNS):\n",
        "            model = NetTest(im_res=im_res, conv1_size=cv1_size, padd_1=pd1, stride_1=st1, dilation_1=dl1).to(device)\n",
        "            if i==0:\n",
        "              macs, params = profile(model, inputs=(torch.randn(1, 1, im_res, im_res).to(device), ))\n",
        "            accs.append(train_model(model))\n",
        "          \n",
        "          # which_model = 'new_res' if a else 'orig_res'\n",
        "          # sol[which_model] = (macs, params, acc)\n",
        "          sol['new_solutions'].append((macs, params, np.mean(accs)))\n",
        "          # accuracies.append((sol, macs, params, acc))\n",
        "          # print(accuracies[-1])\n",
        "          print(sol, '\\n')\n",
        "\n",
        "        except:\n",
        "          print('\\n Model invalid')\n",
        "\n",
        "  \n",
        "  return #sols"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o35rJcNMqkhN"
      },
      "source": [
        "# np.arange(3,8,2)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXpPn7xn2Mfv",
        "outputId": "b3e62847-b2bf-4ec7-c2d9-d88d56c7692e"
      },
      "source": [
        "import random \n",
        "all_res = {}\n",
        "\n",
        "for N1 in [16]:#12,16,20,24]:\n",
        "  all_solutions = []\n",
        "  for C1 in np.arange(3,5,2): # filter size layer 1 \n",
        "    for P1 in np.arange(3): # padding layer 1\n",
        "      for S1 in np.arange(1,3): # stride layer 1    \n",
        "          xx = find_res_params_dilated(N1, C1, P1, S1)\n",
        "          if xx:\n",
        "            all_solutions.append(xx)\n",
        "  \n",
        "  results = []\n",
        "  random.shuffle(all_solutions)\n",
        "  all_solutions.sort(key=len, reverse=True)\n",
        "  all_solutions = all_solutions[:10]\n",
        "  for idx, sol_3 in enumerate(all_solutions):\n",
        "    print(f'\\n --------------------- solution no {idx} -------------------- \\n')\n",
        "\n",
        "    if len(sol_3) > 4:\n",
        "      sol_3 = sol_3[-4:]\n",
        "\n",
        "    evaluate_orig_model(sol_3[0])\n",
        "    if not sol_3[0]['orig_solutions']:\n",
        "      break\n",
        "\n",
        "    evaluate_new_model(sol_3)\n",
        "    xx = (sol_3[0]['orig_solutions'][0], [sol['new_solutions'][0][-1] for sol in sol_3 if sol['new_solutions']])\n",
        "\n",
        "    results.append(xx)\n",
        "\n",
        "  all_res[N1] = results          \n",
        "print(len(all_solutions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " --------------------- solution no 0 -------------------- \n",
            "\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.dropout.Dropout2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.NetTest'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            " Train Epoch: 1/10 [40100/60000 (67%)]\tLoss: 1.424414"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26uxbDiDxX6f"
      },
      "source": [
        "# all_solutions[0]"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zQQFZzZAnz1",
        "outputId": "eb9f52dd-48fb-46d4-dc97-437d8d0ad952"
      },
      "source": [
        "# ([len(x) for x in all_solutions])\n",
        "# sol_3\n",
        "# \n",
        "# len(all_solutions)\n",
        "\n",
        "\n",
        "\n",
        "all_res[N1]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((18100.0, 1990.0, 0.7095666666666668),\n",
              "  [0.6990333333333334, 0.7078333333333333, 0.7146, 0.7155666666666667]),\n",
              " ((29860.0, 3490.0, 0.7931333333333334),\n",
              "  [0.7943666666666668, 0.7947666666666667, 0.7878, 0.7972666666666667])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cPgmIM1mSSU",
        "outputId": "38a49b9c-3e98-40ca-9f30-047112ef4c62"
      },
      "source": [
        "all_solutions[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'im_res_new': 27,\n",
              "  'im_res_orig': 24,\n",
              "  'layer1': [3.0, 10, 2, 9],\n",
              "  'layer1_old': [3, 10, 1, 0],\n",
              "  'layer2': [3.0, 15, 1, 0],\n",
              "  'layer2_old': [3, 15, 1, 0]},\n",
              " {'im_res_new': 27,\n",
              "  'im_res_orig': 24,\n",
              "  'layer1': [3.0, 10, 2, 9],\n",
              "  'layer1_old': [3, 10, 1, 0],\n",
              "  'layer2': [3.0, 15, 2, 9],\n",
              "  'layer2_old': [3, 15, 1, 0]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GhWb1-mmS5a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "x8U-8XrLKrgV",
        "outputId": "e671a1a4-1c42-493c-e081-b7e8b1e4500d"
      },
      "source": [
        "for k in all_res.keys():\n",
        "  means = np.mean(np.array([(x[-1],np.max(y)) for x,y in all_res[k]]), axis=0)\n",
        "  # stds = np.std(np.array([(x[0][-1],np.max(y)) for x,y in all_res[k] ]), axis=0)\n",
        "  plt.plot(means)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVKpqr7n6h0B",
        "outputId": "42eb2af1-2fe6-447e-a67d-59ba36c0cd59"
      },
      "source": [
        "means"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.75759   , 0.82007667])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxHleTnpacj_"
      },
      "source": [
        "for k in all_res.keys():\n",
        "  means = np.mean(np.array([(x[0][-1],y) for x,y in all_res[k] ]), axis=0)\n",
        "  stds = np.std(np.array([(x[0][-1],y) for x,y in all_res[k] ]), axis=0)\n",
        "  plt.plot(means)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKYYYozCrES4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}