{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resolution_idea_solutions_pool.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fw-gSFYIbdu",
        "outputId": "98005610-4ec3-47b6-f013-bd62ecbb582c"
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install thop\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from thop import profile\n",
        "from torchsummary import summary\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.6/dist-packages (0.0.31.post2005241907)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from thop) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9c5QX7BgEp4"
      },
      "source": [
        "# training a model first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN6ifgYqgEp4"
      },
      "source": [
        "use_cuda = True\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT9LC5-AoseA"
      },
      "source": [
        "NUM_MODEL_RUNS = 3\n",
        "EPOCHS = 10"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr39Ia68tUnF"
      },
      "source": [
        "\n",
        "def find_res_fixed_params_pool(N1, C1, S1, P1, C2, S2, P2):\n",
        "  '''\n",
        "    Keeping the number of parameters the same using a pooling layer\n",
        "    Approach II in the paper\n",
        "  '''\n",
        "  num_solutions = 0\n",
        "  Solutions = []\n",
        "\n",
        "  M1 = int((N1 - C1 + 2*P1) / S1 + 1) # output size after conv 1 \n",
        "  # M1 = (N1 - C1 + 2*P1) / S1\n",
        "\n",
        "  for N2 in np.arange(N1+1,29,2): # new resolution\n",
        "    for F in np.arange(2,6): # pooling kernel size\n",
        "      for S in np.arange(1,3): # stride in pool layer\n",
        "        for P in np.arange(F//2): # padding in pool layer\n",
        "          # W1 = (N2 - C1 + 2*P1) / S1\n",
        "          # M2 = (W1 - F + 2*P)  / S\n",
        "          W1 = int((N2 - C1 + 2*P1) / S1 + 1)\n",
        "          M2 = int((W1 - F + 2*P)  / S + 1)\n",
        "\n",
        "          if M1 == M2: #continue\n",
        "\n",
        "          # print(f'1st layer old: inp res: {N1}, filter size: {C1}, num filters: {K1}, out res: {M1}, stride: {S1}, pad: {P1}')\n",
        "          # print(f'1st layer new: inp res: {N2}, filter size: {C1}, num filters: {K1}, out res: {M1}, stride: {S1}, pad: {P1}')\n",
        "          # print(f'pooling layer: inp res: {M1}, filter size: {F},  out res: {M2}, stride: {S}, pad: {P}')\n",
        "          # params_old = (K1 * C1**2 * 1) \n",
        "          # params_new = (K1 * C1**2 * 1) \n",
        "          # # print(f'PARAMs old: {params_old}, PARAMs new: {params_new}\\n')\n",
        "\n",
        "          # assert params_old==params_new, False\n",
        "\n",
        "            num_solutions += 1\n",
        "            Solutions.append({'im_res_orig':N1, 'im_res_new':N2, 'layer1':[C1, S1, P1], 'layer2':[C2, S2, P2], 'pool_layer':[F, S, P]})\n",
        "\n",
        "  # print(f'num solutions: {num_solutions}')\n",
        "  return Solutions  \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcEaJXHJtcNJ"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDttasGMlZ02"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "\n",
        "\n",
        "class NetTest(nn.Module):\n",
        "    def __init__(self, im_res=28, conv1_size=3, conv2_size=3, pool1_size=2, pool2_size=2, num_conv1=10, num_conv2=10, stride_1=1, stride_2=1, padd_1=0, padd_2=0, num_hid=50, pool_layer=None):\n",
        "        super(NetTest, self).__init__()\n",
        "        # import pdb; pdb.set_trace()\n",
        "        self.conv1 = nn.Conv2d(1, num_conv1, kernel_size=conv1_size, stride=stride_1, padding=padd_1, bias=True)\n",
        "        self.res_conv1 = int((im_res - conv1_size + 2*padd_1) / stride_1 + 1)\n",
        "\n",
        "        # plug the new pooling layer\n",
        "        self.new_pool_layer = pool_layer\n",
        "        if self.new_pool_layer:\n",
        "          self.res_conv1 = int((self.res_conv1 - self.new_pool_layer[0] + 2*self.new_pool_layer[2]) / self.new_pool_layer[1] + 1)\n",
        "\n",
        "\n",
        "        # self.res_pool1 = int((self.res_conv1 - pool1_size + 2*0) / pool1_size + 1)                \n",
        "\n",
        "        self.conv2 = nn.Conv2d(num_conv1, num_conv2, kernel_size=conv2_size, stride=stride_2, padding=padd_2, bias=True)\n",
        "        \n",
        "        # print(stride_2)\n",
        "        self.res_conv2 = int((self.res_conv1 - conv2_size + 2*padd_2) / stride_2 + 1 )       \n",
        "        # self.res_pool2 = int((self.res_conv2 - pool2_size + 2*0) / pool2_size + 1)               \n",
        "        \n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "\n",
        "        self.fc1 = nn.Linear((self.res_conv2**2)*num_conv2, num_hid, bias=True)        \n",
        "        self.fc2 = nn.Linear(num_hid, 10, bias=True)\n",
        "        self.pool1_size = pool1_size\n",
        "        self.pool2_size = pool2_size\n",
        "        self.num_conv2 = num_conv2\n",
        "        self.im_res = im_res\n",
        "\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # import pdb; pdb.set_trace()\n",
        "        tmp1 = F.relu(self.conv1(x))\n",
        "        if self.new_pool_layer:\n",
        "          tmp1 = F.relu(F.max_pool2d(tmp1, kernel_size=self.new_pool_layer[0], stride=self.new_pool_layer[1], padding=self.new_pool_layer[2] ))\n",
        "\n",
        "        # tmp1 = F.relu(F.max_pool2d(tmp1, self.pool1_size))\n",
        "        # tmp1 = F.relu(tmp1)\n",
        "        tmp = F.relu(self.conv2_drop(self.conv2(tmp1)))\n",
        "        # x = F.avg_pool2d(tmp, kernel_size=tmp.shape[-1])\n",
        "        # x = x[:,:,0,0]\n",
        "\n",
        "        x = tmp.view(-1, (self.res_conv2**2)*self.num_conv2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x   ### SUPER IMPORTANT ***************************** works with cross entropy loss loss now\n",
        "\n",
        "device = 'cuda'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp9zZ2P6T1Tw"
      },
      "source": [
        "# F.max_pool2d?"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NINTmFMRDpeM"
      },
      "source": [
        "# c = 6\n",
        "# p = 3\n",
        "# s = 2\n",
        "# assert 20 == (28 - c + 2*p) / s + 1, False\n",
        "# 19 = 22 + 2*6 \n",
        "# import cv2\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CGZ2JLFzdgA"
      },
      "source": [
        "def train_model(model):\n",
        "\n",
        "  # EPOCHS = 1\n",
        "  losses = []\n",
        "\n",
        "  optimizer = optim.Adadelta(model.parameters())\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(EPOCHS):\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          \n",
        "          data, target = data.to(device), target.to(device)        \n",
        "          optimizer.zero_grad()\n",
        "          y_pred = model(data) \n",
        "\n",
        "          # import pdb; pdb.set_trace()\n",
        "          loss = F.cross_entropy(y_pred, target)\n",
        "          losses.append(loss.cpu().data)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          # Display\n",
        "          if batch_idx % 100 == 1:\n",
        "              print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch+1,\n",
        "                  EPOCHS,\n",
        "                  batch_idx * len(data), \n",
        "                  len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader), \n",
        "                  loss.cpu().data), \n",
        "                  end='')\n",
        "\n",
        "  # Eval\n",
        "  # model.eval()\n",
        "  # Eval\n",
        "  model.eval()\n",
        "  correct = total = 0\n",
        "  for idx, (images, labels) in enumerate(test_loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      _, pre = torch.max(outputs.data, 1)\n",
        "\n",
        "      total += len(labels)\n",
        "      correct += (pre == labels).sum()\n",
        "\n",
        "  accuracy = float(correct) / total\n",
        "  print('Test Accuracy: %f %%' % accuracy)\n",
        "  # return acc\n",
        "\n",
        "\n",
        "  # import pdb; pdb.set_trace()\n",
        "  # evaluate_x = test_loader.dataset.test_data.type_as(torch.FloatTensor()).to(device)\n",
        "  # evaluate_y = test_loader.dataset.test_labels.to(device)\n",
        "\n",
        "  # output = model(evaluate_x[:,None,...])\n",
        "  # pred = output.data.max(1)[1]\n",
        "  # d = pred.eq(evaluate_y.data).cpu()\n",
        "  # accuracy = d.sum().type(dtype=torch.float64)/d.size()[0]\n",
        "  \n",
        "  print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Test Accuracy: {:.4f}%'.format(\n",
        "      epoch+1,\n",
        "      EPOCHS,\n",
        "      len(train_loader.dataset), \n",
        "      len(train_loader.dataset),\n",
        "      100. * batch_idx / len(train_loader), \n",
        "      loss.cpu().data,\n",
        "      accuracy*100,\n",
        "      end=''))\n",
        "  \n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdlukGiltyP5"
      },
      "source": [
        "# sol_3"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Saj7rxrhL6Z"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIedXhFbNK84"
      },
      "source": [
        "def evaluate_orig_model(sol):\n",
        "\n",
        "  # run the original model for a couple of times\n",
        "  sol['orig_solutions'] = []\n",
        "\n",
        "  cv1_size = sol['layer1'][0]\n",
        "  st1 = sol['layer1'][1]\n",
        "  pd1 = sol['layer1'][2]\n",
        "\n",
        "  cv2_size = sol['layer2'][0]\n",
        "  st2 = sol['layer2'][1]\n",
        "  pd2 = sol['layer2'][2]\n",
        "\n",
        "\n",
        "  im_res = sol['im_res_orig']\n",
        "\n",
        "  global train_loader\n",
        "  global test_loader\n",
        "  \n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      datasets.FashionMNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
        "              transforms.ToTensor(),transforms.Resize((im_res, im_res)),])), batch_size=100, shuffle=True)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      datasets.FashionMNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
        "              transforms.ToTensor(),transforms.Resize((im_res, im_res)),])), batch_size=100, shuffle=True)\n",
        "\n",
        "  # for run_no in range(1):\n",
        "  # try:\n",
        "      # print(f'----  im_res={im_res_new}, conv1_size={cv1_size}, conv2_size={cv2_size}')\n",
        "  # import pdb; pdb.set_trace()\n",
        "  accs = []\n",
        "  for i in range(NUM_MODEL_RUNS):\n",
        "    model = NetTest(im_res=im_res, conv1_size=cv1_size, stride_1=st1, padd_1=pd1, conv2_size=cv2_size, stride_2=st2, padd_2=pd2).to(device)\n",
        "    if i==0:\n",
        "      macs, params = profile(model, inputs=(torch.randn(1, 1, im_res, im_res).to(device), ))\n",
        "    accs.append(train_model(model))\n",
        "  \n",
        "  sol['orig_solutions'].append((macs, params, np.mean(accs)))\n",
        "  # accuracies.append((sol, macs, params, acc))\n",
        "  # print(accuracies[-1])\n",
        "  print(sol, '\\n')\n",
        "\n",
        "  # except:\n",
        "  #   print('\\n Model invalid')\n",
        "\n",
        "\n",
        "  return #sol\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chf2kB7wVinf"
      },
      "source": [
        "def evaluate_new_model(sols):\n",
        "  # running the solutions; one by one; three each\n",
        "  # for run_no\n",
        "\n",
        "  for sol in sols:\n",
        "        im_res = sol['im_res_new']\n",
        "        \n",
        "        cv1_size = sol['layer1'][0]\n",
        "        st1 = sol['layer1'][1]\n",
        "        pd1 = sol['layer1'][2]\n",
        "\n",
        "        cv2_size = sol['layer2'][0]\n",
        "        st2 = sol['layer2'][1]\n",
        "        pd2 = sol['layer2'][2]\n",
        "\n",
        "        pool_lyr = sol['pool_layer']\n",
        "        sol['new_solutions'] = []\n",
        "\n",
        "        global train_loader\n",
        "        global test_loader\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            datasets.FashionMNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),transforms.Resize((im_res, im_res)),])), batch_size=100, shuffle=True)\n",
        "\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            datasets.FashionMNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),transforms.Resize((im_res, im_res)),])), batch_size=100, shuffle=True)\n",
        "\n",
        "\n",
        "        # for run_no in range(1):\n",
        "        # try:\n",
        "          # print(f'----  im_res={im_res_new}, conv1_size={cv1_size}, conv2_size={cv2_size}')\n",
        "        # import pdb; pdb.set_trace()  \n",
        "        accs = []\n",
        "        for i in range(NUM_MODEL_RUNS):\n",
        "          model = NetTest(im_res=im_res, conv1_size=cv1_size, stride_1=st1, padd_1=pd1, conv2_size=cv2_size, stride_2=st2, padd_2=pd2, pool_layer=pool_lyr).to(device)\n",
        "          if i==0:\n",
        "            macs, params = profile(model, inputs=(torch.randn(1, 1, im_res, im_res).to(device), ))\n",
        "          accs.append(train_model(model))\n",
        "        \n",
        "        # which_model = 'new_res' if a else 'orig_res'\n",
        "        # sol[which_model] = (macs, params, acc)\n",
        "        sol['new_solutions'].append((macs, params, np.mean(accs)))\n",
        "        # accuracies.append((sol, macs, params, acc))\n",
        "        # print(accuracies[-1])\n",
        "        print(sol, '\\n')\n",
        "\n",
        "        # except:\n",
        "        #   print('\\n Model invalid')\n",
        "\n",
        "  \n",
        "  return #sols"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o35rJcNMqkhN"
      },
      "source": [
        "# np.arange(3,8,2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXpPn7xn2Mfv",
        "outputId": "2cba4b47-dd8e-4d9d-b3d7-177833b77b65"
      },
      "source": [
        "import random \n",
        "all_res = {}\n",
        "\n",
        "for N1 in [12]:#12,16,20,24]:\n",
        "  all_solutions = []\n",
        "  for C1 in np.arange(3,6,2): # filter size layer 1 \n",
        "    for S1 in np.arange(1,3): # stride layer 1    \n",
        "      for P1 in np.arange(4): # padding layer 1\n",
        "        for C2 in np.arange(3,6,2): # filter size layer 1 \n",
        "          for S2 in np.arange(1,3): # stride layer 1    \n",
        "            for P2 in np.arange(4): # padding layer 1\n",
        "              xx = find_res_fixed_params_pool(N1, C1, S1, P1, C2, S2, P2)\n",
        "              if xx:\n",
        "                all_solutions.append(xx)\n",
        "  \n",
        "  results = []\n",
        "  random.shuffle(all_solutions)\n",
        "  all_solutions.sort(key=len, reverse=True)\n",
        "  all_solutions = all_solutions[:10]\n",
        "  for idx, sol_3 in enumerate(all_solutions):\n",
        "    print(f'\\n --------------------- solution no {idx} -------------------- \\n')\n",
        "    if len(sol_3) > 4:\n",
        "      sol_3 = sol_3[-4:]\n",
        "\n",
        "    evaluate_orig_model(sol_3[0])\n",
        "    if not sol_3[0]['orig_solutions']:\n",
        "      break\n",
        "\n",
        "    evaluate_new_model(sol_3)\n",
        "    xx = (sol_3[0]['orig_solutions'][0], [sol['new_solutions'][0][-1] for sol in sol_3 if sol['new_solutions']])\n",
        "\n",
        "    results.append(xx)\n",
        "\n",
        "  all_res[N1] = results          \n",
        "print(len(all_solutions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " --------------------- solution no 0 -------------------- \n",
            "\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.dropout.Dropout2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.NetTest'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            " Train Epoch: 10/10 [50100/60000 (84%)]\tLoss: 0.553623Test Accuracy: 0.802500 %\n",
            " Train Epoch: 10/10 [60000/60000 (100%)]\tLoss: 0.610690\t Test Accuracy: 80.2500%\n",
            " Train Epoch: 10/10 [50100/60000 (84%)]\tLoss: 0.660086Test Accuracy: 0.806900 %\n",
            " Train Epoch: 10/10 [60000/60000 (100%)]\tLoss: 0.608620\t Test Accuracy: 80.6900%\n",
            " Train Epoch: 10/10 [50100/60000 (84%)]\tLoss: 0.612419Test Accuracy: 0.803800 %\n",
            " Train Epoch: 10/10 [60000/60000 (100%)]\tLoss: 0.509879\t Test Accuracy: 80.3800%\n",
            "{'im_res_orig': 12, 'im_res_new': 23, 'layer1': [5, 2, 0], 'layer2': [5, 2, 2], 'pool_layer': [5, 2, 1], 'orig_solutions': [(16700.0, 5330.0, 0.8043999999999999)]} \n",
            "\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.dropout.Dropout2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.NetTest'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            " Train Epoch: 10/10 [50100/60000 (84%)]\tLoss: 0.688197Test Accuracy: 0.822300 %\n",
            " Train Epoch: 10/10 [60000/60000 (100%)]\tLoss: 0.585615\t Test Accuracy: 82.2300%\n",
            " Train Epoch: 10/10 [50100/60000 (84%)]\tLoss: 0.538115Test Accuracy: 0.816600 %\n",
            " Train Epoch: 10/10 [60000/60000 (100%)]\tLoss: 0.602984\t Test Accuracy: 81.6600%\n",
            " Train Epoch: 10/10 [50100/60000 (84%)]\tLoss: 0.700882Test Accuracy: 0.828100 %\n",
            " Train Epoch: 10/10 [60000/60000 (100%)]\tLoss: 0.548257\t Test Accuracy: 82.8100%\n",
            "{'im_res_orig': 12, 'im_res_new': 23, 'layer1': [5, 2, 0], 'layer2': [5, 2, 2], 'pool_layer': [5, 2, 1], 'orig_solutions': [(16700.0, 5330.0, 0.8043999999999999)], 'new_solutions': [(38540.0, 5330.0, 0.8223333333333334)]} \n",
            "\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.dropout.Dropout2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.NetTest'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            " Train Epoch: 10/10 [50100/60000 (84%)]\tLoss: 0.807467Test Accuracy: 0.823300 %\n",
            " Train Epoch: 10/10 [60000/60000 (100%)]\tLoss: 0.479190\t Test Accuracy: 82.3300%\n",
            " Train Epoch: 1/10 [50100/60000 (84%)]\tLoss: 0.857459"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zQQFZzZAnz1"
      },
      "source": [
        "# ([len(x) for x in all_solutions])\n",
        "sol_3\n",
        "# \n",
        "# len(all_solutions)\n",
        "\n",
        "\n",
        "\n",
        "all_res[N1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cPgmIM1mSSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3c1ccb-abba-4ef9-ec81-6e40b676a9df"
      },
      "source": [
        "all_solutions[0]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'im_res_new': 13,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [2, 1, 0]},\n",
              " {'im_res_new': 13,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [4, 1, 1]},\n",
              " {'im_res_new': 15,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [3, 1, 0]},\n",
              " {'im_res_new': 15,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [5, 1, 1]},\n",
              " {'im_res_new': 17,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [4, 1, 0]},\n",
              " {'im_res_new': 19,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [2, 2, 0]},\n",
              " {'im_res_new': 19,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [4, 2, 1]},\n",
              " {'im_res_new': 19,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [5, 1, 0]},\n",
              " {'im_res_new': 21,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [2, 2, 0]},\n",
              " {'im_res_new': 21,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [3, 2, 0]},\n",
              " {'im_res_new': 21,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [4, 2, 1]},\n",
              " {'im_res_new': 21,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [5, 2, 1]},\n",
              " {'im_res_new': 23,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [3, 2, 0]},\n",
              " {'im_res_new': 23,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [4, 2, 0]},\n",
              " {'im_res_new': 23,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'orig_solutions': [],\n",
              "  'pool_layer': [5, 2, 1]},\n",
              " {'im_res_new': 25,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [4, 2, 0]},\n",
              " {'im_res_new': 25,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [5, 2, 0]},\n",
              " {'im_res_new': 27,\n",
              "  'im_res_orig': 12,\n",
              "  'layer1': [5, 2, 0],\n",
              "  'layer2': [3, 1, 0],\n",
              "  'pool_layer': [5, 2, 0]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GhWb1-mmS5a"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8U-8XrLKrgV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "caf3f82b-c0bd-4d94-bdd3-eedff1609141"
      },
      "source": [
        "for k in all_res.keys():\n",
        "  means = np.mean(np.array([(x[-1],np.max(y)) for x,y in all_res[k]]), axis=0)\n",
        "  # stds = np.std(np.array([(x[0][-1],np.max(y)) for x,y in all_res[k] ]), axis=0)\n",
        "  plt.plot(means)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVKpqr7n6h0B",
        "outputId": "979383b4-5bfd-44ad-c68e-c72e2e7c88f2"
      },
      "source": [
        "means"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.82263667, 0.86711667])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxHleTnpacj_"
      },
      "source": [
        "for k in all_res.keys():\n",
        "  means = np.mean(np.array([(x[0][-1],y) for x,y in all_res[k] ]), axis=0)\n",
        "  stds = np.std(np.array([(x[0][-1],y) for x,y in all_res[k] ]), axis=0)\n",
        "  plt.plot(means)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvJH19_TC3sO"
      },
      "source": [
        "sol_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQHMz9pRjGcr"
      },
      "source": [
        "# FLOPS\n",
        "# http://www.bnikolic.co.uk/blog/python/flops/2019/10/01/pytorch-count-flops.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEym_vLOgEp5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ahq_bgDgEp5"
      },
      "source": [
        "aa = {2:'a'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJBPTzm-kejx"
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwpWkGRZlWsO"
      },
      "source": [
        "colors = ['blue', 'red', 'green', ]\n",
        "for idx,i in enumerate([7,14,28]):\n",
        "  plt.plot(np.log(pars[ress==i]), score[ress==i] , 'o', color = colors[idx])\n",
        "\n",
        "plt.legend(['res = 7', 'res = 14', 'res = 28'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjPLszlGlaY4"
      },
      "source": [
        "colors = ['blue', 'red', 'green', ]\n",
        "for idx,i in enumerate([7,14,28]):\n",
        "  plt.plot(np.log(flops[ress==i]), score[ress==i] , 'o', color = colors[idx])\n",
        "\n",
        "plt.legend(['res = 7', 'res = 14', 'res = 28'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9DPWCI0mq-r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FqAhvbIobLN"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YovErL0-oUEs"
      },
      "source": [
        "# ls MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kmPE3U2of2t"
      },
      "source": [
        "cd drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N15rtEEdolUm"
      },
      "source": [
        "# cd /MyDrive/classification_images/Pairwise\n",
        "!cd MyDrive/ClassificationImages/Pairwise/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG_7x65oonJS"
      },
      "source": [
        "# from google.colab import files\n",
        "# # \n",
        "# with open('example.txt', 'w') as f:\n",
        "#   f.write('some content')\n",
        "\n",
        "# files.download('example.txt')\n",
        "\n",
        "\n",
        "\n",
        "# with open('MyDrive/ClassificationImages/Pairwise/accs_mnist.npz', 'w') as f:\n",
        "np.savez('MyDrive/ClassificationImages/Pairwise/accs_fmnist.npz', accs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNss-tWspL-P"
      },
      "source": [
        "# with open('MyDrive/ClassificationImages/Pairwise/accs_mnist.npz') as f:\n",
        "dd = np.load('MyDrive/ClassificationImages/Pairwise/accs_mnist.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g07IsyKrqM7x"
      },
      "source": [
        "# accs = dd['arr_0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIeLykpBqNQD"
      },
      "source": [
        "def test_f(aa):\n",
        "  aa.append(10)\n",
        "\n",
        "  return\n",
        "\n",
        "q = [1]\n",
        "test_f(q)\n",
        "print(q)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKYYYozCrES4"
      },
      "source": [
        "torch.__version__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak6fzUmEAGGU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}